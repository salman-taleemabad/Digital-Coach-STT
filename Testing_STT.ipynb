{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc83cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adab digital Nayat Koch apke Classroom culture ki bhatkare to wahabi kuch bhatiri ki gunjai bachon ki dharmiyan tavun or ichtemai amalko barhava deniki koshishkare mislan group work Kezari jaha bache milkar javabat KE javab de or Apni raika tabad lakare tafani mahal bhi banai mislan kahaniya sunane kevakt ab talaba kobhi shamil kare bahatari kijanip gamzan rahe shukriya subhanallahi hamdi shukriya spanallah.\n"
     ]
    }
   ],
   "source": [
    "import assemblyai as aai\n",
    "\n",
    "aai.settings.api_key = \"fc2ff7e25bc8447ea67c3f1d86ea8f5d\"\n",
    "\n",
    "# audio_file = \"./local_file.mp3\"\n",
    "audio_file = r\"Data\\response (1).wav\"\n",
    "    \n",
    "config = aai.TranscriptionConfig(speech_model=aai.SpeechModel.best)\n",
    "\n",
    "transcript = aai.Transcriber(config=config).transcribe(audio_file)\n",
    "\n",
    "if transcript.status == \"error\":\n",
    "  raise RuntimeError(f\"Transcription failed: {transcript.error}\")\n",
    "\n",
    "print(transcript.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291584ef",
   "metadata": {},
   "source": [
    "## AZURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f42762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure Speech-to-Text with Speaker Diarization\n",
      "1. Transcribe from microphone\n",
      "2. Transcribe from audio file\n",
      "Error: File '' does not exist\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "def speech_to_text_with_diarization_from_file(audio_file_path, language=\"ur-IN\"):\n",
    "    \"\"\"\n",
    "    Transcribe audio from a file with speaker diarization\n",
    "    \n",
    "    Parameters:\n",
    "        audio_file_path (str): Path to the audio file (.wav format recommended)\n",
    "        language (str): The language code to use (default: ur-IN for Urdu)\n",
    "    \"\"\"\n",
    "    # Get speech key and region from environment variables\n",
    "    speech_key = os.environ.get('SPEECH_KEY')\n",
    "    speech_region = os.environ.get('SPEECH_REGION')\n",
    "    \n",
    "    if not speech_key or not speech_region:\n",
    "        print(\"Error: Missing SPEECH_KEY or SPEECH_REGION environment variables\")\n",
    "        print(\"Please set them with your Azure Speech Service credentials\")\n",
    "        return\n",
    "        \n",
    "    # Configure speech recognition\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "    speech_config.speech_recognition_language = language\n",
    "    \n",
    "    # Create audio configuration from file\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=audio_file_path)\n",
    "    \n",
    "    # Create conversation transcriber\n",
    "    conversation_transcriber = speechsdk.transcription.ConversationTranscriber(\n",
    "        speech_config=speech_config, \n",
    "        audio_config=audio_config\n",
    "    )\n",
    "    \n",
    "    # Enable diarization for intermediate results\n",
    "    conversation_transcriber.properties.set_property(\n",
    "        speechsdk.PropertyId.SpeechServiceResponse_DiarizeIntermediateResults,\n",
    "        \"true\"\n",
    "    )\n",
    "    \n",
    "    # Setup result handlers\n",
    "    done = False\n",
    "    \n",
    "    def handle_final_result(evt):\n",
    "        speaker = evt.result.user_id if evt.result.user_id else \"Unknown\"\n",
    "        print(f\"FINAL: Speaker {speaker}: {evt.result.text}\")\n",
    "    \n",
    "    def handle_intermediate_result(evt):\n",
    "        speaker = evt.result.user_id if evt.result.user_id else \"Unknown\"\n",
    "        print(f\"INTERIM: Speaker {speaker}: {evt.result.text}\")\n",
    "    \n",
    "    def handle_session_stopped(evt):\n",
    "        nonlocal done\n",
    "        print(f\"Session stopped: {evt}\")\n",
    "        done = True\n",
    "    \n",
    "    def handle_canceled(evt):\n",
    "        nonlocal done\n",
    "        print(f\"CANCELED: {evt.cancellation_details.reason}\")\n",
    "        if evt.cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(f\"CANCELED: Error Code={evt.cancellation_details.error_code}\")\n",
    "            print(f\"CANCELED: Error Details={evt.cancellation_details.error_details}\")\n",
    "        done = True\n",
    "    \n",
    "    # Connect callbacks\n",
    "    conversation_transcriber.transcribed.connect(handle_final_result)\n",
    "    conversation_transcriber.transcribing.connect(handle_intermediate_result)\n",
    "    conversation_transcriber.session_stopped.connect(handle_session_stopped)\n",
    "    conversation_transcriber.canceled.connect(handle_canceled)\n",
    "    \n",
    "    # Start continuous recognition\n",
    "    print(f\"Starting transcription with speaker diarization for language: {language}\")\n",
    "    conversation_transcriber.start_transcribing_async()\n",
    "    \n",
    "    # Wait for completion or user interrupt\n",
    "    try:\n",
    "        while not done:\n",
    "            time.sleep(0.5)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Stopping transcription...\")\n",
    "    finally:\n",
    "        conversation_transcriber.stop_transcribing_async()\n",
    "\n",
    "\n",
    "def speech_to_text_with_diarization_from_mic(language=\"ur-IN\"):\n",
    "    \"\"\"\n",
    "    Transcribe audio from microphone with speaker diarization\n",
    "    \n",
    "    Parameters:\n",
    "        language (str): The language code to use (default: ur-IN for Urdu)\n",
    "    \"\"\"\n",
    "    # Get speech key and region from environment variables\n",
    "    speech_key = os.environ.get('SPEECH_KEY')\n",
    "    speech_region = os.environ.get('SPEECH_REGION')\n",
    "    \n",
    "    if not speech_key or not speech_region:\n",
    "        print(\"Error: Missing SPEECH_KEY or SPEECH_REGION environment variables\")\n",
    "        print(\"Please set them with your Azure Speech Service credentials\")\n",
    "        return\n",
    "        \n",
    "    # Configure speech recognition\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "    speech_config.speech_recognition_language = language\n",
    "    \n",
    "    # Create audio configuration for microphone\n",
    "    audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "    \n",
    "    # Create conversation transcriber\n",
    "    conversation_transcriber = speechsdk.transcription.ConversationTranscriber(\n",
    "        speech_config=speech_config, \n",
    "        audio_config=audio_config\n",
    "    )\n",
    "    \n",
    "    # Enable diarization for intermediate results\n",
    "    conversation_transcriber.properties.set_property(\n",
    "        speechsdk.PropertyId.SpeechServiceResponse_DiarizeIntermediateResults,\n",
    "        \"true\"\n",
    "    )\n",
    "    \n",
    "    # Setup result handlers\n",
    "    done = False\n",
    "    \n",
    "    def handle_final_result(evt):\n",
    "        speaker = evt.result.user_id if evt.result.user_id else \"Unknown\"\n",
    "        print(f\"FINAL: Speaker {speaker}: {evt.result.text}\")\n",
    "    \n",
    "    def handle_intermediate_result(evt):\n",
    "        speaker = evt.result.user_id if evt.result.user_id else \"Unknown\"\n",
    "        print(f\"INTERIM: Speaker {speaker}: {evt.result.text}\")\n",
    "    \n",
    "    def handle_session_stopped(evt):\n",
    "        nonlocal done\n",
    "        print(f\"Session stopped: {evt}\")\n",
    "        done = True\n",
    "    \n",
    "    def handle_canceled(evt):\n",
    "        nonlocal done\n",
    "        print(f\"CANCELED: {evt.cancellation_details.reason}\")\n",
    "        if evt.cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(f\"CANCELED: Error Code={evt.cancellation_details.error_code}\")\n",
    "            print(f\"CANCELED: Error Details={evt.cancellation_details.error_details}\")\n",
    "        done = True\n",
    "    \n",
    "    # Connect callbacks\n",
    "    conversation_transcriber.transcribed.connect(handle_final_result)\n",
    "    conversation_transcriber.transcribing.connect(handle_intermediate_result)\n",
    "    conversation_transcriber.session_stopped.connect(handle_session_stopped)\n",
    "    conversation_transcriber.canceled.connect(handle_canceled)\n",
    "    \n",
    "    # Start continuous recognition\n",
    "    print(f\"Starting microphone transcription with speaker diarization for language: {language}\")\n",
    "    print(\"Speak into your microphone...\")\n",
    "    print(\"Press Ctrl+C to stop\")\n",
    "    conversation_transcriber.start_transcribing_async()\n",
    "    \n",
    "    # Wait for completion or user interrupt\n",
    "    try:\n",
    "        while not done:\n",
    "            time.sleep(0.5)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Stopping transcription...\")\n",
    "    finally:\n",
    "        conversation_transcriber.stop_transcribing_async()\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the example\"\"\"\n",
    "    print(\"Azure Speech-to-Text with Speaker Diarization\")\n",
    "    print(\"1. Transcribe from microphone\")\n",
    "    print(\"2. Transcribe from audio file\")\n",
    "    \n",
    "    choice = input(\"Select an option (1 or 2): \")\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        # Get language code (optional)\n",
    "        language = input(\"Enter language code (press Enter for Urdu/ur-IN): \") or \"ur-IN\"\n",
    "        speech_to_text_with_diarization_from_mic(language)\n",
    "    elif choice == \"2\":\n",
    "        # Get file path\n",
    "        file_path = input(\"Enter audio file path: \")\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Error: File '{file_path}' does not exist\")\n",
    "            return\n",
    "            \n",
    "        # Get language code (optional)\n",
    "        language = input(\"Enter language code (press Enter for Urdu/ur-IN): \") or \"ur-IN\"\n",
    "        speech_to_text_with_diarization_from_file(file_path, language)\n",
    "    else:\n",
    "        print(\"Invalid option selected\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75e8b18",
   "metadata": {},
   "source": [
    "## Google Cloud Speech-to-Text API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c370c2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import subprocess\n",
    "import tempfile\n",
    "import shutil\n",
    "import time\n",
    "import logging\n",
    "import glob # For finding chunk files\n",
    "from google.cloud import speech_v1p1beta1 as speech\n",
    "from google.api_core import exceptions as google_exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2b05742",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_LANGUAGE_CODE = \"ur-PK\"  # Language for transcription\n",
    "TARGET_SAMPLE_RATE_HZ = 16000    # Sample rate for chunks (should match your input FLAC)\n",
    "CHUNK_DURATION_SECONDS = 55      # Duration of each audio chunk (max 59 for safety)\n",
    "MAX_API_RETRIES = 3              # Max retries for a single chunk transcription\n",
    "RETRY_INITIAL_DELAY_SECONDS = 5  # Initial delay between retries (will double each time)\n",
    "OUTPUT_TRANSCRIPT_FILENAME = \"full_transcription_from_local_chunks.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d80ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(module)s - %(funcName)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10afa2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranscriptionError(Exception):\n",
    "    \"\"\"Custom exception for transcription failures.\"\"\"\n",
    "    pass\n",
    "\n",
    "def check_ffmpeg_installed():\n",
    "    \"\"\"Checks if ffmpeg is installed and accessible.\"\"\"\n",
    "    logger.info(\"Checking for ffmpeg installation...\")\n",
    "    try:\n",
    "        subprocess.run([\"ffmpeg\", \"-version\"], capture_output=True, check=True, text=True)\n",
    "        logger.info(\"ffmpeg found.\")\n",
    "        return True\n",
    "    except (subprocess.CalledProcessError, FileNotFoundError) as e:\n",
    "        logger.error(f\"ffmpeg not found or not executable. Please ensure ffmpeg is installed and in your system's PATH. Error: {e}\")\n",
    "        return False\n",
    "\n",
    "def segment_audio_ffmpeg(input_audio_path, output_dir, chunk_duration_s, target_sample_rate_hz):\n",
    "    \"\"\"\n",
    "    Segments the input audio file into smaller chunks using ffmpeg.\n",
    "    Assumes input_audio_path is already in FLAC format at target_sample_rate_hz.\n",
    "\n",
    "    Args:\n",
    "        input_audio_path (str): Path to the long input audio file (FLAC).\n",
    "        output_dir (str): Directory to save the audio chunks.\n",
    "        chunk_duration_s (int): Desired duration of each chunk in seconds.\n",
    "        target_sample_rate_hz (int): The sample rate of the input audio.\n",
    "\n",
    "    Returns:\n",
    "        list: A sorted list of paths to the created audio chunk files.\n",
    "              Returns an empty list if segmentation fails.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Starting audio segmentation for: {input_audio_path}\")\n",
    "    logger.info(f\"Chunk duration: {chunk_duration_s}s, Output directory: {output_dir}\")\n",
    "\n",
    "    if not os.path.exists(input_audio_path):\n",
    "        logger.error(f\"Input audio file not found: {input_audio_path}\")\n",
    "        return []\n",
    "\n",
    "    # Output chunk filename pattern\n",
    "    chunk_filename_pattern = os.path.join(output_dir, f\"chunk_%04d.flac\")\n",
    "\n",
    "    # ffmpeg command to segment the audio.\n",
    "    # -i: input file\n",
    "    # -f segment: output format is segment\n",
    "    # -segment_time: duration of each segment\n",
    "    # -c copy: copy the codec (assumes input is already FLAC and properly encoded)\n",
    "    #          This is faster and avoids re-encoding if input is already good.\n",
    "    # -ar: audio sample rate (to ensure consistency, though -c copy should preserve it)\n",
    "    # -ac 1: audio channels (mono)\n",
    "    ffmpeg_command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\", input_audio_path,\n",
    "        \"-f\", \"segment\",\n",
    "        \"-segment_time\", str(chunk_duration_s),\n",
    "        \"-c\", \"copy\", # Assuming input is already FLAC, mono, 16000Hz\n",
    "        chunk_filename_pattern,\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        logger.info(f\"Executing ffmpeg command: {' '.join(ffmpeg_command)}\")\n",
    "        process = subprocess.run(ffmpeg_command, capture_output=True, text=True, check=True)\n",
    "        logger.info(\"ffmpeg segmentation successful.\")\n",
    "        logger.debug(f\"ffmpeg stdout:\\n{process.stdout}\")\n",
    "        logger.debug(f\"ffmpeg stderr:\\n{process.stderr}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        logger.error(f\"ffmpeg segmentation failed. Return code: {e.returncode}\")\n",
    "        logger.error(f\"ffmpeg stdout:\\n{e.stdout}\")\n",
    "        logger.error(f\"ffmpeg stderr:\\n{e.stderr}\")\n",
    "        return []\n",
    "    except FileNotFoundError:\n",
    "        logger.error(\"ffmpeg command not found. Ensure ffmpeg is installed and in PATH.\")\n",
    "        return []\n",
    "\n",
    "    # Find all created chunk files and sort them\n",
    "    # Using glob.glob to find files matching the pattern\n",
    "    chunk_files = sorted(glob.glob(os.path.join(output_dir, \"chunk_*.flac\")))\n",
    "\n",
    "    if not chunk_files:\n",
    "        logger.warning(\"No chunk files were created by ffmpeg. Check ffmpeg output and input file.\")\n",
    "    else:\n",
    "        logger.info(f\"Created {len(chunk_files)} audio chunks.\")\n",
    "\n",
    "    return chunk_files\n",
    "\n",
    "def transcribe_single_chunk_with_retry(\n",
    "    speech_client,\n",
    "    chunk_path,\n",
    "    language_code,\n",
    "    sample_rate_hz,\n",
    "    max_retries=MAX_API_RETRIES,\n",
    "    initial_delay_s=RETRY_INITIAL_DELAY_SECONDS\n",
    "):\n",
    "    \"\"\"\n",
    "    Transcribes a single audio chunk using Google Speech-to-Text with retries for transient errors.\n",
    "\n",
    "    Args:\n",
    "        speech_client: Initialized SpeechClient.\n",
    "        chunk_path (str): Path to the audio chunk file.\n",
    "        language_code (str): Language code for transcription.\n",
    "        sample_rate_hz (int): Sample rate of the audio chunk.\n",
    "        max_retries (int): Maximum number of retry attempts.\n",
    "        initial_delay_s (int): Initial delay in seconds for retries (exponential backoff).\n",
    "\n",
    "    Returns:\n",
    "        str: The transcript of the chunk, or an empty string if transcription fails after retries.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Transcribing chunk: {os.path.basename(chunk_path)}\")\n",
    "\n",
    "    if not os.path.exists(chunk_path):\n",
    "        logger.error(f\"Chunk file not found: {chunk_path}\")\n",
    "        return \"\"\n",
    "    \n",
    "    try:\n",
    "        with io.open(chunk_path, \"rb\") as audio_file:\n",
    "            content = audio_file.read()\n",
    "    except IOError as e:\n",
    "        logger.error(f\"Could not read chunk file {chunk_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "    audio_input = speech.RecognitionAudio(content=content)\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.FLAC, # Assuming chunks are FLAC\n",
    "        sample_rate_hertz=sample_rate_hz,\n",
    "        language_code=language_code,\n",
    "        enable_automatic_punctuation=True,\n",
    "        # model=\"latest_short\", # You can specify a model if needed\n",
    "    )\n",
    "\n",
    "    current_retry = 0\n",
    "    delay = initial_delay_s\n",
    "    while current_retry <= max_retries:\n",
    "        try:\n",
    "            response = speech_client.recognize(config=config, audio=audio_input)\n",
    "            \n",
    "            chunk_transcript = \"\"\n",
    "            if response.results:\n",
    "                for result in response.results:\n",
    "                    chunk_transcript += result.alternatives[0].transcript + \" \"\n",
    "                logger.info(f\"Successfully transcribed chunk: {os.path.basename(chunk_path)}\")\n",
    "                return chunk_transcript.strip()\n",
    "            else:\n",
    "                logger.warning(f\"No speech detected or transcription result for chunk: {os.path.basename(chunk_path)}\")\n",
    "                return \"\" # No result, no need to retry for this specific case\n",
    "\n",
    "        except google_exceptions.RetryError as e: # Typically covers DeadlineExceeded, ServiceUnavailable\n",
    "            logger.warning(f\"API RetryError for chunk {os.path.basename(chunk_path)} (Attempt {current_retry+1}/{max_retries+1}): {e}. Retrying in {delay}s...\")\n",
    "        except google_exceptions.ServiceUnavailable as e:\n",
    "            logger.warning(f\"API ServiceUnavailable for chunk {os.path.basename(chunk_path)} (Attempt {current_retry+1}/{max_retries+1}): {e}. Retrying in {delay}s...\")\n",
    "        except google_exceptions.DeadlineExceeded as e:\n",
    "            logger.warning(f\"API DeadlineExceeded for chunk {os.path.basename(chunk_path)} (Attempt {current_retry+1}/{max_retries+1}): {e}. Retrying in {delay}s...\")\n",
    "        except google_exceptions.GoogleAPIError as e:\n",
    "            logger.error(f\"Non-retryable Google API error for chunk {os.path.basename(chunk_path)}: {e}\")\n",
    "            return \"\" # For other API errors (like PermissionDenied, InvalidArgument), don't retry\n",
    "\n",
    "        time.sleep(delay)\n",
    "        current_retry += 1\n",
    "        delay *= 2  # Exponential backoff\n",
    "\n",
    "    logger.error(f\"Failed to transcribe chunk {os.path.basename(chunk_path)} after {max_retries} retries.\")\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def transcribe_long_local_audio_by_chunking(\n",
    "    local_long_audio_path,\n",
    "    output_transcript_file=OUTPUT_TRANSCRIPT_FILENAME,\n",
    "    language_code=DEFAULT_LANGUAGE_CODE,\n",
    "    target_sample_rate=TARGET_SAMPLE_RATE_HZ,\n",
    "    chunk_duration=CHUNK_DURATION_SECONDS\n",
    "):\n",
    "    \"\"\"\n",
    "    Transcribes a long local audio file by chunking it and processing each chunk.\n",
    "\n",
    "    Args:\n",
    "        local_long_audio_path (str): Path to the long input audio file (FLAC format recommended).\n",
    "        output_transcript_file (str): Path to save the final combined transcript.\n",
    "        language_code (str): BCP-47 language code for transcription.\n",
    "        target_sample_rate (int): The sample rate your audio file is (and chunks will be).\n",
    "        chunk_duration (int): Duration of each audio chunk in seconds.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if transcription was successful (even if partially), False otherwise.\n",
    "    \"\"\"\n",
    "    logger.info(f\"--- Starting long local audio transcription process for: {local_long_audio_path} ---\")\n",
    "\n",
    "    if not check_ffmpeg_installed():\n",
    "        return False # Prerequisite not met\n",
    "\n",
    "    if not os.path.exists(local_long_audio_path):\n",
    "        logger.error(f\"Input audio file does not exist: {local_long_audio_path}\")\n",
    "        return False\n",
    "\n",
    "    temp_chunk_dir = None\n",
    "    try:\n",
    "        # Create a temporary directory for audio chunks\n",
    "        temp_chunk_dir = tempfile.mkdtemp(prefix=\"audio_chunks_\")\n",
    "        logger.info(f\"Created temporary directory for chunks: {temp_chunk_dir}\")\n",
    "\n",
    "        # Step 1: Segment the audio file into chunks\n",
    "        chunk_file_paths = segment_audio_ffmpeg(\n",
    "            local_long_audio_path, temp_chunk_dir, chunk_duration, target_sample_rate\n",
    "        )\n",
    "\n",
    "        if not chunk_file_paths:\n",
    "            logger.error(\"Audio segmentation failed or produced no chunks. Aborting.\")\n",
    "            raise TranscriptionError(\"Audio segmentation failed.\")\n",
    "\n",
    "        # Step 2: Initialize Speech-to-Text client\n",
    "        try:\n",
    "            speech_client = speech.SpeechClient()\n",
    "            logger.info(\"Google Cloud Speech client initialized successfully.\")\n",
    "        except google_exceptions.DefaultCredentialsError as e:\n",
    "            logger.error(f\"Google Cloud Default Credentials not found. Ensure you've run 'gcloud auth application-default login'. Error: {e}\")\n",
    "            raise TranscriptionError(\"Authentication failed.\") from e\n",
    "        except Exception as e: # Catch any other client initialization errors\n",
    "            logger.error(f\"Failed to initialize Google Cloud Speech client: {e}\")\n",
    "            raise TranscriptionError(\"Speech client initialization failed.\") from e\n",
    "\n",
    "        # Step 3: Transcribe each chunk\n",
    "        all_transcripts_segments = []\n",
    "        processed_chunks = 0\n",
    "        for i, chunk_path in enumerate(chunk_file_paths):\n",
    "            logger.info(f\"Processing chunk {i + 1}/{len(chunk_file_paths)}: {os.path.basename(chunk_path)}\")\n",
    "            transcript_segment = transcribe_single_chunk_with_retry(\n",
    "                speech_client, chunk_path, language_code, target_sample_rate\n",
    "            )\n",
    "            if transcript_segment: # Append even if it's just spaces, to maintain order if needed\n",
    "                all_transcripts_segments.append(transcript_segment)\n",
    "            processed_chunks +=1\n",
    "            # Optional: Progress update\n",
    "            if processed_chunks % 5 == 0 or processed_chunks == len(chunk_file_paths):\n",
    "                 logger.info(f\"Progress: {processed_chunks}/{len(chunk_file_paths)} chunks submitted for transcription.\")\n",
    "\n",
    "\n",
    "        # Step 4: Combine transcripts and save to file\n",
    "        if not all_transcripts_segments:\n",
    "            logger.warning(\"No transcription segments were generated from any chunk.\")\n",
    "            # Depending on requirements, this could be an error or just an empty result.\n",
    "            # For now, we'll write an empty file.\n",
    "            final_transcript = \"\"\n",
    "        else:\n",
    "            final_transcript = \"\\n\".join(all_transcripts_segments).strip() # Use newline, or \" \" for continuous text\n",
    "\n",
    "        logger.info(f\"Writing combined transcript to: {output_transcript_file}\")\n",
    "        try:\n",
    "            with open(output_transcript_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(final_transcript)\n",
    "            logger.info(\"Successfully wrote transcript to file.\")\n",
    "        except IOError as e:\n",
    "            logger.error(f\"Failed to write transcript to file {output_transcript_file}: {e}\")\n",
    "            # Don't raise TranscriptionError here, as transcription might have partially succeeded.\n",
    "            # The transcript is in final_transcript variable.\n",
    "\n",
    "        if not final_transcript and len(chunk_file_paths) > 0 :\n",
    "            logger.warning(\"Transcription process completed, but the resulting transcript is empty.\")\n",
    "        elif final_transcript:\n",
    "             logger.info(\"--- Transcription process completed successfully. ---\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    except TranscriptionError as e: # Catch custom errors for aborting conditions\n",
    "        logger.error(f\"A critical error occurred during transcription: {e}\")\n",
    "        return False\n",
    "    except Exception as e: # Catch-all for unexpected errors\n",
    "        logger.exception(f\"An unexpected error occurred: {e}\") # .exception includes stack trace\n",
    "        return False\n",
    "    finally:\n",
    "        # Step 5: Cleanup temporary directory\n",
    "        if temp_chunk_dir and os.path.exists(temp_chunk_dir):\n",
    "            try:\n",
    "                shutil.rmtree(temp_chunk_dir)\n",
    "                logger.info(f\"Successfully cleaned up temporary chunk directory: {temp_chunk_dir}\")\n",
    "            except OSError as e:\n",
    "                logger.error(f\"Error cleaning up temporary directory {temp_chunk_dir}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abf4838c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 10:55:24 - INFO - 1896180177 - <module> - Script started.\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Script started.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247f6828",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_audio_file_path = r\"D:\\Taleemabad\\Digital Coach\\Dataset\\Urban II\\918-IMCG I-8-4\\Obs 1-918_converted.flac\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44d51229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 10:57:06 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - --- Starting long local audio transcription process for: D:\\Taleemabad\\Digital Coach\\Dataset\\Urban II\\918-IMCG I-8-4\\Obs 1-918_converted.flac ---\n",
      "2025-05-12 10:57:06 - INFO - 2400712708 - check_ffmpeg_installed - Checking for ffmpeg installation...\n",
      "2025-05-12 10:57:06 - INFO - 2400712708 - check_ffmpeg_installed - ffmpeg found.\n",
      "2025-05-12 10:57:06 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Created temporary directory for chunks: C:\\Users\\mypc\\AppData\\Local\\Temp\\audio_chunks_04yk84vv\n",
      "2025-05-12 10:57:06 - INFO - 2400712708 - segment_audio_ffmpeg - Starting audio segmentation for: D:\\Taleemabad\\Digital Coach\\Dataset\\Urban II\\918-IMCG I-8-4\\Obs 1-918_converted.flac\n",
      "2025-05-12 10:57:06 - INFO - 2400712708 - segment_audio_ffmpeg - Chunk duration: 55s, Output directory: C:\\Users\\mypc\\AppData\\Local\\Temp\\audio_chunks_04yk84vv\n",
      "2025-05-12 10:57:06 - INFO - 2400712708 - segment_audio_ffmpeg - Executing ffmpeg command: ffmpeg -i D:\\Taleemabad\\Digital Coach\\Dataset\\Urban II\\918-IMCG I-8-4\\Obs 1-918_converted.flac -f segment -segment_time 55 -c copy C:\\Users\\mypc\\AppData\\Local\\Temp\\audio_chunks_04yk84vv\\chunk_%04d.flac\n",
      "2025-05-12 10:57:07 - INFO - 2400712708 - segment_audio_ffmpeg - ffmpeg segmentation successful.\n",
      "2025-05-12 10:57:07 - INFO - 2400712708 - segment_audio_ffmpeg - Created 31 audio chunks.\n",
      "2025-05-12 10:57:09 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Google Cloud Speech client initialized successfully.\n",
      "2025-05-12 10:57:09 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 1/31: chunk_0000.flac\n",
      "2025-05-12 10:57:09 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0000.flac\n",
      "2025-05-12 10:57:11 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0000.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:11 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 2/31: chunk_0001.flac\n",
      "2025-05-12 10:57:11 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0001.flac\n",
      "2025-05-12 10:57:12 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0001.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:12 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 3/31: chunk_0002.flac\n",
      "2025-05-12 10:57:12 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0002.flac\n",
      "2025-05-12 10:57:12 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0002.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:12 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 4/31: chunk_0003.flac\n",
      "2025-05-12 10:57:12 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0003.flac\n",
      "2025-05-12 10:57:13 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0003.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:13 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 5/31: chunk_0004.flac\n",
      "2025-05-12 10:57:13 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0004.flac\n",
      "2025-05-12 10:57:14 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0004.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:14 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Progress: 5/31 chunks submitted for transcription.\n",
      "2025-05-12 10:57:14 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 6/31: chunk_0005.flac\n",
      "2025-05-12 10:57:14 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0005.flac\n",
      "2025-05-12 10:57:15 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0005.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:15 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 7/31: chunk_0006.flac\n",
      "2025-05-12 10:57:15 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0006.flac\n",
      "2025-05-12 10:57:16 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0006.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:16 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 8/31: chunk_0007.flac\n",
      "2025-05-12 10:57:16 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0007.flac\n",
      "2025-05-12 10:57:17 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0007.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:17 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 9/31: chunk_0008.flac\n",
      "2025-05-12 10:57:17 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0008.flac\n",
      "2025-05-12 10:57:18 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0008.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:18 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 10/31: chunk_0009.flac\n",
      "2025-05-12 10:57:18 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0009.flac\n",
      "2025-05-12 10:57:19 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0009.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:19 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Progress: 10/31 chunks submitted for transcription.\n",
      "2025-05-12 10:57:19 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 11/31: chunk_0010.flac\n",
      "2025-05-12 10:57:19 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0010.flac\n",
      "2025-05-12 10:57:19 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0010.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:19 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 12/31: chunk_0011.flac\n",
      "2025-05-12 10:57:19 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0011.flac\n",
      "2025-05-12 10:57:20 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0011.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:20 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 13/31: chunk_0012.flac\n",
      "2025-05-12 10:57:20 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0012.flac\n",
      "2025-05-12 10:57:21 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0012.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:21 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 14/31: chunk_0013.flac\n",
      "2025-05-12 10:57:21 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0013.flac\n",
      "2025-05-12 10:57:22 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0013.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:22 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 15/31: chunk_0014.flac\n",
      "2025-05-12 10:57:22 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0014.flac\n",
      "2025-05-12 10:57:23 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0014.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:23 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Progress: 15/31 chunks submitted for transcription.\n",
      "2025-05-12 10:57:23 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 16/31: chunk_0015.flac\n",
      "2025-05-12 10:57:23 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0015.flac\n",
      "2025-05-12 10:57:23 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0015.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:23 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 17/31: chunk_0016.flac\n",
      "2025-05-12 10:57:23 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0016.flac\n",
      "2025-05-12 10:57:24 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0016.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:24 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 18/31: chunk_0017.flac\n",
      "2025-05-12 10:57:24 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0017.flac\n",
      "2025-05-12 10:57:25 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0017.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:25 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 19/31: chunk_0018.flac\n",
      "2025-05-12 10:57:25 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0018.flac\n",
      "2025-05-12 10:57:26 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0018.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:26 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 20/31: chunk_0019.flac\n",
      "2025-05-12 10:57:26 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0019.flac\n",
      "2025-05-12 10:57:27 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0019.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:27 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Progress: 20/31 chunks submitted for transcription.\n",
      "2025-05-12 10:57:27 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 21/31: chunk_0020.flac\n",
      "2025-05-12 10:57:27 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0020.flac\n",
      "2025-05-12 10:57:28 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0020.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:28 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 22/31: chunk_0021.flac\n",
      "2025-05-12 10:57:28 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0021.flac\n",
      "2025-05-12 10:57:28 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0021.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:28 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 23/31: chunk_0022.flac\n",
      "2025-05-12 10:57:28 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0022.flac\n",
      "2025-05-12 10:57:29 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0022.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:29 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 24/31: chunk_0023.flac\n",
      "2025-05-12 10:57:29 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0023.flac\n",
      "2025-05-12 10:57:30 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0023.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:30 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 25/31: chunk_0024.flac\n",
      "2025-05-12 10:57:30 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0024.flac\n",
      "2025-05-12 10:57:31 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0024.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:31 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Progress: 25/31 chunks submitted for transcription.\n",
      "2025-05-12 10:57:31 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 26/31: chunk_0025.flac\n",
      "2025-05-12 10:57:31 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0025.flac\n",
      "2025-05-12 10:57:31 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0025.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:31 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 27/31: chunk_0026.flac\n",
      "2025-05-12 10:57:31 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0026.flac\n",
      "2025-05-12 10:57:32 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0026.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:32 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 28/31: chunk_0027.flac\n",
      "2025-05-12 10:57:32 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0027.flac\n",
      "2025-05-12 10:57:33 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0027.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:33 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 29/31: chunk_0028.flac\n",
      "2025-05-12 10:57:33 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0028.flac\n",
      "2025-05-12 10:57:34 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0028.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:34 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 30/31: chunk_0029.flac\n",
      "2025-05-12 10:57:34 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0029.flac\n",
      "2025-05-12 10:57:35 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0029.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:35 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Progress: 30/31 chunks submitted for transcription.\n",
      "2025-05-12 10:57:35 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Processing chunk 31/31: chunk_0030.flac\n",
      "2025-05-12 10:57:35 - INFO - 2400712708 - transcribe_single_chunk_with_retry - Transcribing chunk: chunk_0030.flac\n",
      "2025-05-12 10:57:35 - ERROR - 2400712708 - transcribe_single_chunk_with_retry - Non-retryable Google API error for chunk chunk_0030.flac: 403 Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"speech.googleapis.com\"\n",
      "}\n",
      "metadata {\n",
      "  key: \"consumer\"\n",
      "  value: \"projects/764086051850\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"Your application is authenticating by using local Application Default Credentials. The speech.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n",
      "]\n",
      "2025-05-12 10:57:35 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Progress: 31/31 chunks submitted for transcription.\n",
      "2025-05-12 10:57:35 - WARNING - 2400712708 - transcribe_long_local_audio_by_chunking - No transcription segments were generated from any chunk.\n",
      "2025-05-12 10:57:35 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Writing combined transcript to: full_transcription_from_local_chunks.txt\n",
      "2025-05-12 10:57:35 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Successfully wrote transcript to file.\n",
      "2025-05-12 10:57:35 - WARNING - 2400712708 - transcribe_long_local_audio_by_chunking - Transcription process completed, but the resulting transcript is empty.\n",
      "2025-05-12 10:57:35 - INFO - 2400712708 - transcribe_long_local_audio_by_chunking - Successfully cleaned up temporary chunk directory: C:\\Users\\mypc\\AppData\\Local\\Temp\\audio_chunks_04yk84vv\n",
      "2025-05-12 10:57:35 - INFO - 706761493 - <module> - Script finished. Check 'full_transcription_from_local_chunks.txt' for results.\n"
     ]
    }
   ],
   "source": [
    "success = transcribe_long_local_audio_by_chunking(\n",
    "            local_long_audio_path=input_audio_file_path,\n",
    "            output_transcript_file=OUTPUT_TRANSCRIPT_FILENAME,\n",
    "            language_code=DEFAULT_LANGUAGE_CODE,\n",
    "            target_sample_rate=TARGET_SAMPLE_RATE_HZ,\n",
    "            chunk_duration=CHUNK_DURATION_SECONDS\n",
    "        )\n",
    "\n",
    "if success:\n",
    "    logger.info(f\"Script finished. Check '{OUTPUT_TRANSCRIPT_FILENAME}' for results.\")\n",
    "else:\n",
    "    logger.error(\"Script finished with errors. Please review the logs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc8dbee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8e88f82",
   "metadata": {},
   "source": [
    "# OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e7d01b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement pyaudioop (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for pyaudioop\n"
     ]
    }
   ],
   "source": [
    "!pip install pyaudioop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bb398fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in d:\\taleemabad\\digital coach\\venv\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: openai in d:\\taleemabad\\digital coach\\venv\\lib\\site-packages (1.78.1)\n",
      "Requirement already satisfied: python-dotenv in d:\\taleemabad\\digital coach\\venv\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\taleemabad\\digital coach\\venv\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\taleemabad\\digital coach\\venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\taleemabad\\digital coach\\venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\taleemabad\\digital coach\\venv\\lib\\site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\taleemabad\\digital coach\\venv\\lib\\site-packages (from openai) (2.11.4)\n",
      "Requirement already satisfied: sniffio in d:\\taleemabad\\digital coach\\venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\taleemabad\\digital coach\\venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\taleemabad\\digital coach\\venv\\lib\\site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\taleemabad\\digital coach\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in d:\\taleemabad\\digital coach\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\taleemabad\\digital coach\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\taleemabad\\digital coach\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\taleemabad\\digital coach\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\taleemabad\\digital coach\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\taleemabad\\digital coach\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Requirement already satisfied: colorama in d:\\taleemabad\\digital coach\\venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbdf704",
   "metadata": {},
   "source": [
    "## Simple Transcription into Urdu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca5909b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting audio...\n",
      "Loading audio file: Dataset\\Urban II\\918-IMCG I-8-4\\Obs 1-918.m4a\n",
      "Created 67 chunks from 1651.2s audio\n",
      "Transcribing chunks...\n",
      "Transcribing chunk 1/67...\n",
      "Chunk 1 done: آپنے بکس بنائیں اوپر یہ پیری پ...\n",
      "Transcribing chunk 2/67...\n",
      "Chunk 2 done: یا بیٹھیں گے ابیں تھوڑا سا یہ ...\n",
      "Transcribing chunk 3/67...\n",
      "Chunk 3 done: اب جب ہم نے کلاغ بنائے اور ہم ...\n",
      "Transcribing chunk 4/67...\n",
      "Chunk 4 done: GG اور ہم نے ہنٹس بھی بنانی سک...\n",
      "Transcribing chunk 5/67...\n",
      "Chunk 5 done: اور اس کے اندروں سے تک تری ہین...\n",
      "Transcribing chunk 6/67...\n",
      "Chunk 6 done: جو minute hand ہے big hand وہ ...\n",
      "Transcribing chunk 7/67...\n",
      "Chunk 7 done: دو دو منٹ ہنڈ دو ہار ہند ہے ای...\n",
      "Transcribing chunk 8/67...\n",
      "Chunk 8 done: اگر آپ مجھے بتائیں گے اگر اس ک...\n",
      "Transcribing chunk 9/67...\n",
      "Chunk 9 done: اگلے بیٹے کو ڈوائٹ کریں گے اور...\n",
      "Transcribing chunk 10/67...\n",
      "Chunk 10 done: ...\n",
      "Transcribing chunk 11/67...\n",
      "Chunk 11 done: اب آپ دیکھیں ایک دن دو حصوں می...\n",
      "Transcribing chunk 12/67...\n",
      "Chunk 12 done: بابا جی کا پھر جہاں ہماری کلاک...\n",
      "Transcribing chunk 13/67...\n",
      "Chunk 13 done: لیکن ہم اسے کیسے سمجھیں گے؟ ہم...\n",
      "Transcribing chunk 14/67...\n",
      "Chunk 14 done: ایم اور پیم کریں گے اور ہم دیک...\n",
      "Transcribing chunk 15/67...\n",
      "Chunk 15 done: آپ دیکھو میرے دن یہاں پر آگیا ...\n",
      "Transcribing chunk 16/67...\n",
      "Chunk 16 done: ڈیو ڈی ایڈا میم میں ای ایم میں...\n",
      "Transcribing chunk 17/67...\n",
      "Chunk 17 done: یہ ہمارا یہاں تک آؤرز بنیتے ہی...\n",
      "Transcribing chunk 18/67...\n",
      "Chunk 18 done: ...\n",
      "Transcribing chunk 19/67...\n",
      "Chunk 19 done: سکول پر ہی تیار بھی ہو سکتے ہی...\n",
      "Transcribing chunk 20/67...\n",
      "Chunk 20 done: آپ کیا کہتے ہیں سکول سٹارٹڈ ای...\n",
      "Transcribing chunk 21/67...\n",
      "Chunk 21 done: سمجھتے ہیں کہ ہم سن کے ساتھ ہی...\n",
      "Transcribing chunk 22/67...\n",
      "Chunk 22 done: ...\n",
      "Transcribing chunk 23/67...\n",
      "Chunk 23 done: اب آپ دیکھیں میں نے 130 پر ہمی...\n",
      "Transcribing chunk 24/67...\n",
      "Chunk 24 done: پھر 2.30 تک آپ بھر پہنچ گئے پھ...\n",
      "Transcribing chunk 25/67...\n",
      "Chunk 25 done: بہت خوبصورت ہے آپ پی ایم پر پہ...\n",
      "Transcribing chunk 26/67...\n",
      "Chunk 26 done: میں تو سو جاؤں گی تھوڑا سا اور...\n",
      "Transcribing chunk 27/67...\n",
      "Chunk 27 done: ...\n",
      "Transcribing chunk 28/67...\n",
      "Chunk 28 done: مہم خان دینر کر کے سو جائیں گے...\n",
      "Transcribing chunk 29/67...\n",
      "Chunk 29 done: اچھا نائن پی ایم ہو گیا اب ہم ...\n",
      "Transcribing chunk 30/67...\n",
      "Chunk 30 done: ہم کھولیں گے پھر تب ہم زیادہ ہ...\n",
      "Transcribing chunk 31/67...\n",
      "Chunk 31 done: 3 ایم ہم سو رہے ہوں گے 4 ایم ہ...\n",
      "Transcribing chunk 32/67...\n",
      "Chunk 32 done: بہت آگے چلی گئی ہوتی ہے نا ہاں...\n",
      "Transcribing chunk 33/67...\n",
      "Chunk 33 done: یہ دیکھیں لیکن شہروانیہ کم ہے ...\n",
      "Transcribing chunk 34/67...\n",
      "Chunk 34 done: ...\n",
      "Transcribing chunk 35/67...\n",
      "Chunk 35 done: ڈیکوں کے پیسے ویڈریس اوپر لے ل...\n",
      "Transcribing chunk 36/67...\n",
      "Chunk 36 done: ...\n",
      "Transcribing chunk 37/67...\n",
      "Chunk 37 done: ڈیویڈ ڈیویڈ...\n",
      "Transcribing chunk 38/67...\n",
      "Chunk 38 done: ...\n",
      "Transcribing chunk 39/67...\n",
      "Chunk 39 done: ڈھانڈ ڈھانڈ ڈھانڈ...\n",
      "Transcribing chunk 40/67...\n",
      "Chunk 40 done: ...\n",
      "Transcribing chunk 41/67...\n",
      "Chunk 41 done: اچھا ایسے کرنے اور اپنی کرن پر...\n",
      "Transcribing chunk 42/67...\n",
      "Chunk 42 done: ایک سائیڈ پر کیا ہے نوں ہے ایک...\n",
      "Transcribing chunk 43/67...\n",
      "Chunk 43 done: 12 ہارز دیئے ہوئے ہیں نوموں او...\n",
      "Transcribing chunk 44/67...\n",
      "Chunk 44 done: کسی کو ہیڈ پر پیش کھو دیں گے ا...\n",
      "Transcribing chunk 45/67...\n",
      "Chunk 45 done: اور یہ بتائیں کہ مجھے کہ جب ہم...\n",
      "Transcribing chunk 46/67...\n",
      "Chunk 46 done: ...\n",
      "Transcribing chunk 47/67...\n",
      "Chunk 47 done: ...\n",
      "Transcribing chunk 48/67...\n",
      "Chunk 48 done: اس کو تر کر گرے ہیں اس کو تر ک...\n",
      "Transcribing chunk 49/67...\n",
      "Chunk 49 done: What time does Fatima come bac...\n",
      "Transcribing chunk 50/67...\n",
      "Chunk 50 done: ...\n",
      "Transcribing chunk 51/67...\n",
      "Chunk 51 done: پی اے م وہ کونسے ٹائم ہوگا پی ...\n",
      "Transcribing chunk 52/67...\n",
      "Chunk 52 done: اب آپ ایسا کریں گے کہ آج جو گھ...\n",
      "Transcribing chunk 53/67...\n",
      "Chunk 53 done: یہ اچھا لگے گا آپ ایک پیش کیوپ...\n",
      "Transcribing chunk 54/67...\n",
      "Chunk 54 done: جب تک جو بھی ایکوڈی کریں اس وق...\n",
      "Transcribing chunk 55/67...\n",
      "Chunk 55 done: کیا کر رہے تھے کوئی دوسرے کیا ...\n",
      "Transcribing chunk 56/67...\n",
      "Chunk 56 done: کہ آپ نے بس سمجھ آگئے ہے یا نہ...\n",
      "Transcribing chunk 57/67...\n",
      "Chunk 57 done: ہانیا سات بجے جھکتی ہے اب میں ...\n",
      "Transcribing chunk 58/67...\n",
      "Chunk 58 done: آئیشہ شام کو پانچ لگے کھینے جا...\n",
      "Transcribing chunk 59/67...\n",
      "Chunk 59 done: پور ایم مجھے صحیح ہے؟ نہیں شام...\n",
      "Transcribing chunk 60/67...\n",
      "Chunk 60 done: اور ہم نے دیکھا تھا کہ کھڑو کھ...\n",
      "Transcribing chunk 61/67...\n",
      "Chunk 61 done: یہ صحیح ہے یا چلتا ہے؟ بچے آتے...\n",
      "Transcribing chunk 62/67...\n",
      "Chunk 62 done: ملے راہ پیچھے میں آپ کو صبح کس...\n",
      "Transcribing chunk 63/67...\n",
      "Chunk 63 done: ...\n",
      "Transcribing chunk 64/67...\n",
      "Chunk 64 done: ...\n",
      "Transcribing chunk 65/67...\n",
      "Chunk 65 done: ہمارے پاس اچھا دل ہے، آپ کیسے ...\n",
      "Transcribing chunk 66/67...\n",
      "Chunk 66 done: ۹ۤ۶۷۹۸۹ۨ۟۹۹۹ۧۻۥ۷ۦ۰ۚۨۯ۰ۯۯ۽ۧۤ۷ۯۤ...\n",
      "Transcribing chunk 67/67...\n",
      "Chunk 67 done: امیر بھائی...\n",
      "Transcription complete and saved to transcription.txt\n",
      "آپنے بکس بنائیں اوپر یہ پیری پیری بکس بنائیں اور آرہے ہیں 6 وقت آج اچھا اکٹیوٹی کریں گے وہ ہم کریں گے پیچ نمبر 155 اب کوئی بات نہیں ہے اگر آپ نے بکس نہیں فرمائیں تو کوئی بات نہیں ہے مجھے کوئی بات نہیں تھی اب یہ کھوڑا سرے یہ دے دیں کہ ہم نے وقت دے دی کہ کیا پڑھیں گے ہم نے وقت دے دیں یا بیٹھیں گے ابیں تھوڑا سا یہ لیتے ہیں کیا پڑھا تھا ہم نے پڑھا تھا جب ہم ٹائم کا پلیس ہو گئے تھے ہم نے کلاک بنانے سے دیکھیں ہم نے دیکھا تھا کتنے آورز ہوتے ہیں 24 آورز 24 آورز There are 24 hours in a day مطلب جب ہم نے ...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from pydub import AudioSegment\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API Key\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def simple_chunk_audio(audio_path, chunk_size_ms=30000, overlap_ms=5000):\n",
    "    \"\"\"Split audio into chunks with minimal dependencies\"\"\"\n",
    "    print(f\"Loading audio file: {audio_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Load audio file\n",
    "        audio = AudioSegment.from_file(audio_path)\n",
    "        \n",
    "        # Get audio duration\n",
    "        duration_ms = len(audio)\n",
    "        \n",
    "        # Calculate step size\n",
    "        step_ms = chunk_size_ms - overlap_ms\n",
    "        \n",
    "        # Create chunks\n",
    "        chunks = []\n",
    "        for start_ms in range(0, duration_ms, step_ms):\n",
    "            end_ms = min(start_ms + chunk_size_ms, duration_ms)\n",
    "            chunk = audio[start_ms:end_ms]\n",
    "            chunks.append(chunk)\n",
    "            \n",
    "        print(f\"Created {len(chunks)} chunks from {duration_ms/1000:.1f}s audio\")\n",
    "        return chunks\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading audio: {e}\")\n",
    "        print(\"Make sure ffmpeg is installed for handling audio files\")\n",
    "        raise\n",
    "\n",
    "def transcribe_chunks(chunks, client, language=\"ur\"):\n",
    "    \"\"\"Transcribe each chunk using the OpenAI API\"\"\"\n",
    "    transcriptions = []\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Transcribing chunk {i+1}/{len(chunks)}...\")\n",
    "        \n",
    "        # Create temporary file\n",
    "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')\n",
    "        temp_path = temp_file.name\n",
    "        temp_file.close()\n",
    "        \n",
    "        try:\n",
    "            # Export chunk to temporary file\n",
    "            chunk.export(temp_path, format=\"mp3\")\n",
    "            \n",
    "            # Transcribe using OpenAI API\n",
    "            with open(temp_path, 'rb') as audio_file:\n",
    "                response = client.audio.transcriptions.create(\n",
    "                    model=\"whisper-1\",\n",
    "                    file=audio_file,\n",
    "                    language=language\n",
    "                )\n",
    "                \n",
    "            transcriptions.append(response.text)\n",
    "            print(f\"Chunk {i+1} done: {response.text[:30]}...\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing chunk {i+1}: {e}\")\n",
    "            transcriptions.append(\"[Error transcribing this segment]\")\n",
    "            \n",
    "        finally:\n",
    "            # Clean up\n",
    "            if os.path.exists(temp_path):\n",
    "                os.remove(temp_path)\n",
    "    \n",
    "    return transcriptions\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    # Path to your audio file\n",
    "    audio_path = r\"Dataset\\Urban II\\918-IMCG I-8-4\\Obs 1-918.m4a\"\n",
    "    \n",
    "    # Use a try-except block to catch any errors\n",
    "    try:\n",
    "        print(\"Splitting audio...\")\n",
    "        chunks = simple_chunk_audio(audio_path)\n",
    "        \n",
    "        print(\"Transcribing chunks...\")\n",
    "        transcriptions = transcribe_chunks(chunks, client)\n",
    "        \n",
    "        # Combine transcriptions\n",
    "        full_text = \" \".join(transcriptions)\n",
    "        \n",
    "        # Save the result\n",
    "        with open(\"transcription.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(full_text)\n",
    "        \n",
    "        print(\"Transcription complete and saved to transcription.txt\")\n",
    "        print(full_text[:500] + \"...\")  # Show the first 500 characters\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        # Provide a backup solution\n",
    "        try_alternative_solution()\n",
    "\n",
    "def try_alternative_solution():\n",
    "    \"\"\"Backup solution that tries to transcribe the whole file at once\"\"\"\n",
    "    print(\"\\nTrying alternative approach: direct transcription...\")\n",
    "    audio_path = r\"Dataset\\Urban II\\918-IMCG I-8-4\\Obs 1-918.m4a\"\n",
    "    \n",
    "    try:\n",
    "        with open(audio_path, \"rb\") as audio_file:\n",
    "            response = client.audio.transcriptions.create(\n",
    "                model=\"whisper-1\",\n",
    "                file=audio_file,\n",
    "                language=\"ur\"\n",
    "            )\n",
    "        \n",
    "        # Save transcription\n",
    "        with open(\"transcription_direct.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(response.text)\n",
    "        \n",
    "        print(\"Direct transcription successful! Saved to transcription_direct.txt\")\n",
    "        print(response.text[:500] + \"...\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Direct transcription also failed: {e}\")\n",
    "        print(\"\\nIf both methods fail, you may need to:\")\n",
    "        print(\"1. Ensure ffmpeg is installed (needed for pydub)\")\n",
    "        print(\"2. Manually split your audio file using software like Audacity\")\n",
    "        print(\"3. Transcribe each part separately\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9854214d",
   "metadata": {},
   "source": [
    "## What if we tranlate it into English?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e77625d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting audio...\n",
      "Loading audio file: Dataset\\Urban II\\918-IMCG I-8-4\\Obs 1-918.m4a\n",
      "Created 67 chunks from 1651.2s audio\n",
      "Translating chunks...\n",
      "Translating chunk 1/67...\n",
      "Chunk 1 done: We have made a lot of blogs an...\n",
      "Translating chunk 2/67...\n",
      "Chunk 2 done: Now, let's take a look at what...\n",
      "Translating chunk 3/67...\n",
      "Chunk 3 done: When we made the clock and saw...\n",
      "Translating chunk 4/67...\n",
      "Chunk 4 done: And we also learned how to mak...\n",
      "Translating chunk 5/67...\n",
      "Chunk 5 done: And there are three hands in i...\n",
      "Translating chunk 6/67...\n",
      "Chunk 6 done: Where is the minute hand? Here...\n",
      "Translating chunk 7/67...\n",
      "Chunk 7 done: Eleven. Twelve. Our end is at ...\n",
      "Translating chunk 8/67...\n",
      "Chunk 8 done: If you count your hours, there...\n",
      "Translating chunk 9/67...\n",
      "Chunk 9 done: We will divide it and you will...\n",
      "Translating chunk 10/67...\n",
      "Chunk 10 done: Eleven, twelve. Twelve. Good a...\n",
      "Translating chunk 11/67...\n",
      "Chunk 11 done: Now we will see that one day i...\n",
      "Translating chunk 12/67...\n",
      "Chunk 12 done: Then when we turn the clock, i...\n",
      "Translating chunk 13/67...\n",
      "Chunk 13 done: But how will we understand it?...\n",
      "Translating chunk 14/67...\n",
      "Chunk 14 done: M for Pregnant M for Post-Preg...\n",
      "Translating chunk 15/67...\n",
      "Chunk 15 done: You see, the main thing is tha...\n",
      "Translating chunk 16/67...\n",
      "Chunk 16 done: I am an illustrator. Ma'am, I ...\n",
      "Translating chunk 17/67...\n",
      "Chunk 17 done: This is our AM time and this i...\n",
      "Translating chunk 18/67...\n",
      "Chunk 18 done: We will have to study in the m...\n",
      "Translating chunk 19/67...\n",
      "Chunk 19 done: You can get ready for school. ...\n",
      "Translating chunk 20/67...\n",
      "Chunk 20 done: What do you say? School starts...\n",
      "Translating chunk 21/67...\n",
      "Chunk 21 done: It started at 8.30am. And then...\n",
      "Translating chunk 22/67...\n",
      "Chunk 22 done: What time do you go to night c...\n",
      "Translating chunk 23/67...\n",
      "Chunk 23 done: Now you see, we will have a ho...\n",
      "Translating chunk 24/67...\n",
      "Chunk 24 done: What did you do when you reach...\n",
      "Translating chunk 25/67...\n",
      "Chunk 25 done: Very good. You have reached Pi...\n",
      "Translating chunk 26/67...\n",
      "Chunk 26 done: I will go to sleep. I will go ...\n",
      "Translating chunk 27/67...\n",
      "Chunk 27 done: We will have to go out for a b...\n",
      "Translating chunk 28/67...\n",
      "Chunk 28 done: Ma'am, we will have dinner and...\n",
      "Translating chunk 29/67...\n",
      "Chunk 29 done: It's 9pm. What are we doing no...\n",
      "Translating chunk 30/67...\n",
      "Chunk 30 done: If we sleep, we'll be healthie...\n",
      "Translating chunk 31/67...\n",
      "Chunk 31 done: 3 am we will be sleeping 4 am ...\n",
      "Translating chunk 32/67...\n",
      "Chunk 32 done: No, no, no, no. You have gone ...\n",
      "Translating chunk 33/67...\n",
      "Chunk 33 done: See this. Because there are le...\n",
      "Translating chunk 34/67...\n",
      "Chunk 34 done: It's a very practical way. You...\n",
      "Translating chunk 35/67...\n",
      "Chunk 35 done: ...\n",
      "Translating chunk 36/67...\n",
      "Chunk 36 done: ...\n",
      "Translating chunk 37/67...\n",
      "Chunk 37 done: ...\n",
      "Translating chunk 38/67...\n",
      "Chunk 38 done: What are you reading? I am rea...\n",
      "Translating chunk 39/67...\n",
      "Chunk 39 done: ...\n",
      "Translating chunk 40/67...\n",
      "Chunk 40 done: ...\n",
      "Translating chunk 41/67...\n",
      "Chunk 41 done: Now we will take this later in...\n",
      "Translating chunk 42/67...\n",
      "Chunk 42 done: One hundred and fifty-five. On...\n",
      "Translating chunk 43/67...\n",
      "Chunk 43 done: There are 12 hours between noo...\n",
      "Translating chunk 44/67...\n",
      "Chunk 44 done: Do it, do it, don't help anyon...\n",
      "Translating chunk 45/67...\n",
      "Chunk 45 done: And tell me, when we are havin...\n",
      "Translating chunk 46/67...\n",
      "Chunk 46 done: ...\n",
      "Translating chunk 47/67...\n",
      "Chunk 47 done: ...\n",
      "Translating chunk 48/67...\n",
      "Chunk 48 done: Let's go down and get it. Let'...\n",
      "Translating chunk 49/67...\n",
      "Chunk 49 done: What time does Fatima come bac...\n",
      "Translating chunk 50/67...\n",
      "Chunk 50 done: I'll tell you. What time? 10 o...\n",
      "Translating chunk 51/67...\n",
      "Chunk 51 done: P M What time will that be? P ...\n",
      "Translating chunk 52/67...\n",
      "Chunk 52 done: I am going to do it. Now you w...\n",
      "Translating chunk 53/67...\n",
      "Chunk 53 done: It will look good. You will ma...\n",
      "Translating chunk 54/67...\n",
      "Chunk 54 done: At that time, whatever activit...\n",
      "Translating chunk 55/67...\n",
      "Chunk 55 done: What were they doing at that t...\n",
      "Translating chunk 56/67...\n",
      "Chunk 56 done: I will tell you if you have un...\n",
      "Translating chunk 57/67...\n",
      "Chunk 57 done: Hania wakes up at 7am. I just ...\n",
      "Translating chunk 58/67...\n",
      "Chunk 58 done: Ayesha goes to play football a...\n",
      "Translating chunk 59/67...\n",
      "Chunk 59 done: 4 M. Is it right? No. In the e...\n",
      "Translating chunk 60/67...\n",
      "Chunk 60 done: And we saw that what happens a...\n",
      "Translating chunk 61/67...\n",
      "Chunk 61 done: Is it right or wrong?...\n",
      "Translating chunk 62/67...\n",
      "Chunk 62 done: I will tell you in the morning...\n",
      "Translating chunk 63/67...\n",
      "Chunk 63 done: ...\n",
      "Translating chunk 64/67...\n",
      "Chunk 64 done: It would have been easier, rig...\n",
      "Translating chunk 65/67...\n",
      "Chunk 65 done: How will you do it? Good. Why ...\n",
      "Translating chunk 66/67...\n",
      "Error processing chunk 66: <!DOCTYPE html>\n",
      "<!--[if lt IE 7]> <html class=\"no-js ie6 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 7]>    <html class=\"no-js ie7 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 8]>    <html class=\"no-js ie8 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if gt IE 8]><!--> <html class=\"no-js\" lang=\"en-US\"> <!--<![endif]-->\n",
      "<head>\n",
      "\n",
      "\n",
      "<title>api.openai.com | 520: Web server is returning an unknown error</title>\n",
      "<meta charset=\"UTF-8\" />\n",
      "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\n",
      "<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\" />\n",
      "<meta name=\"robots\" content=\"noindex, nofollow\" />\n",
      "<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\n",
      "<link rel=\"stylesheet\" id=\"cf_styles-css\" href=\"/cdn-cgi/styles/main.css\" />\n",
      "\n",
      "\n",
      "</head>\n",
      "<body>\n",
      "<div id=\"cf-wrapper\">\n",
      "    <div id=\"cf-error-details\" class=\"p-0\">\n",
      "        <header class=\"mx-auto pt-10 lg:pt-6 lg:px-8 w-240 lg:w-full mb-8\">\n",
      "            <h1 class=\"inline-block sm:block sm:mb-2 font-light text-60 lg:text-4xl text-black-dark leading-tight mr-2\">\n",
      "              <span class=\"inline-block\">Web server is returning an unknown error</span>\n",
      "              <span class=\"code-label\">Error code 520</span>\n",
      "            </h1>\n",
      "            <div>\n",
      "               Visit <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_520&utm_campaign=api.openai.com\" target=\"_blank\" rel=\"noopener noreferrer\">cloudflare.com</a> for more information.\n",
      "            </div>\n",
      "            <div class=\"mt-3\">2025-05-16 03:59:16 UTC</div>\n",
      "        </header>\n",
      "        <div class=\"my-8 bg-gradient-gray\">\n",
      "            <div class=\"w-240 lg:w-full mx-auto\">\n",
      "                <div class=\"clearfix md:px-8\">\n",
      "                  \n",
      "<div id=\"cf-browser-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    \n",
      "    <span class=\"cf-icon-browser block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    \n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">You</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    \n",
      "    Browser\n",
      "    \n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\n",
      "</div>\n",
      "\n",
      "<div id=\"cf-cloudflare-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_520&utm_campaign=api.openai.com\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
      "    <span class=\"cf-icon-cloud block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    </a>\n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">Islamabad</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_520&utm_campaign=api.openai.com\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
      "    Cloudflare\n",
      "    </a>\n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\n",
      "</div>\n",
      "\n",
      "<div id=\"cf-host-status\" class=\"cf-error-source relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    \n",
      "    <span class=\"cf-icon-server block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-error w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    \n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">api.openai.com</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    \n",
      "    Host\n",
      "    \n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-red-error\">Error</span>\n",
      "</div>\n",
      "\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"w-240 lg:w-full mx-auto mb-8 lg:px-8\">\n",
      "            <div class=\"clearfix\">\n",
      "                <div class=\"w-1/2 md:w-full float-left pr-6 md:pb-10 md:pr-0 leading-relaxed\">\n",
      "                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What happened?</h2>\n",
      "                    <p>There is an unknown connection issue between Cloudflare and the origin web server. As a result, the web page can not be displayed.</p>\n",
      "                </div>\n",
      "                <div class=\"w-1/2 md:w-full float-left leading-relaxed\">\n",
      "                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What can I do?</h2>\n",
      "                          <h3 class=\"text-15 font-semibold mb-2\">If you are a visitor of this website:</h3>\n",
      "      <p class=\"mb-6\">Please try again in a few minutes.</p>\n",
      "\n",
      "      <h3 class=\"text-15 font-semibold mb-2\">If you are the owner of this website:</h3>\n",
      "      <p><span>There is an issue between Cloudflare's cache and your origin web server. Cloudflare monitors for these errors and automatically investigates the cause. To help support the investigation, you can pull the corresponding error log from your web server and submit it our support team.  Please include the Ray ID (which is at the bottom of this error page).</span> <a rel=\"noopener noreferrer\" href=\"https://developers.cloudflare.com/support/troubleshooting/http-status-codes/cloudflare-5xx-errors/error-520/\">Additional troubleshooting resources</a>.</p>\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"cf-error-footer cf-wrapper w-240 lg:w-full py-10 sm:py-4 sm:px-8 mx-auto text-center sm:text-left border-solid border-0 border-t border-gray-300\">\n",
      "  <p class=\"text-13\">\n",
      "    <span class=\"cf-footer-item sm:block sm:mb-1\">Cloudflare Ray ID: <strong class=\"font-semibold\">9407f46b1c454122</strong></span>\n",
      "    <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\n",
      "    <span id=\"cf-footer-item-ip\" class=\"cf-footer-item hidden sm:block sm:mb-1\">\n",
      "      Your IP:\n",
      "      <button type=\"button\" id=\"cf-footer-ip-reveal\" class=\"cf-footer-ip-reveal-btn\">Click to reveal</button>\n",
      "      <span class=\"hidden\" id=\"cf-footer-ip\">124.109.40.186</span>\n",
      "      <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\n",
      "    </span>\n",
      "    <span class=\"cf-footer-item sm:block sm:mb-1\"><span>Performance &amp; security by</span> <a rel=\"noopener noreferrer\" href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_520&utm_campaign=api.openai.com\" id=\"brand_link\" target=\"_blank\">Cloudflare</a></span>\n",
      "    \n",
      "  </p>\n",
      "  <script>(function(){function d(){var b=a.getElementById(\"cf-footer-item-ip\"),c=a.getElementById(\"cf-footer-ip-reveal\");b&&\"classList\"in b&&(b.classList.remove(\"hidden\"),c.addEventListener(\"click\",function(){c.classList.add(\"hidden\");a.getElementById(\"cf-footer-ip\").classList.remove(\"hidden\")}))}var a=document;document.addEventListener&&a.addEventListener(\"DOMContentLoaded\",d)})();</script>\n",
      "</div><!-- /.error-footer -->\n",
      "\n",
      "\n",
      "    </div>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "Translating chunk 67/67...\n",
      "Error processing chunk 67: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Translation complete and saved to english_translation.txt\n",
      "We have made a lot of blogs and here we are at page 6. Time. Today we are going to do page number 155. It's okay if you haven't opened the books yet. I will open it and you can read it. Take a little time. We don't have time. What are you reading? We are reading. Now, let's take a look at what we have studied so far. We have studied about the clock. When we were doing time calculation, we learned how to make a clock. And we saw how many hours are there in one day. 24 hours. There are 24 hours in...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from pydub import AudioSegment\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API Key\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def chunk_audio(audio_path, chunk_size_ms=30000, overlap_ms=5000):\n",
    "    \"\"\"Split audio into chunks\"\"\"\n",
    "    print(f\"Loading audio file: {audio_path}\")\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    duration_ms = len(audio)\n",
    "    step_ms = chunk_size_ms - overlap_ms\n",
    "    \n",
    "    chunks = []\n",
    "    for start_ms in range(0, duration_ms, step_ms):\n",
    "        end_ms = min(start_ms + chunk_size_ms, duration_ms)\n",
    "        chunk = audio[start_ms:end_ms]\n",
    "        chunks.append(chunk)\n",
    "    \n",
    "    print(f\"Created {len(chunks)} chunks from {duration_ms/1000:.1f}s audio\")\n",
    "    return chunks\n",
    "\n",
    "def translate_chunks(chunks, client):\n",
    "    \"\"\"Translate each chunk from Urdu to English\"\"\"\n",
    "    translations = []\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Translating chunk {i+1}/{len(chunks)}...\")\n",
    "        \n",
    "        # Create temporary file\n",
    "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')\n",
    "        temp_path = temp_file.name\n",
    "        temp_file.close()\n",
    "        \n",
    "        try:\n",
    "            # Export chunk to temporary file\n",
    "            chunk.export(temp_path, format=\"mp3\")\n",
    "            \n",
    "            # Translate using OpenAI API\n",
    "            with open(temp_path, 'rb') as audio_file:\n",
    "                response = client.audio.translations.create(\n",
    "                    model=\"whisper-1\",\n",
    "                    file=audio_file\n",
    "                )\n",
    "                \n",
    "            translations.append(response.text)\n",
    "            print(f\"Chunk {i+1} done: {response.text[:30]}...\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing chunk {i+1}: {e}\")\n",
    "            translations.append(\"[Error translating this segment]\")\n",
    "            \n",
    "        finally:\n",
    "            # Clean up\n",
    "            if os.path.exists(temp_path):\n",
    "                os.remove(temp_path)\n",
    "    \n",
    "    return translations\n",
    "\n",
    "# Main execution\n",
    "audio_path = r\"Dataset\\Urban II\\918-IMCG I-8-4\\Obs 1-918.m4a\"\n",
    "\n",
    "\n",
    "print(\"Splitting audio...\")\n",
    "chunks = chunk_audio(audio_path)\n",
    "\n",
    "print(\"Translating chunks...\")\n",
    "translations = translate_chunks(chunks, client)\n",
    "\n",
    "# Combine translations\n",
    "full_text = \" \".join(translations)\n",
    "\n",
    "# Save the result\n",
    "with open(\"english_translation.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(full_text)\n",
    "\n",
    "print(\"Translation complete and saved to english_translation.txt\")\n",
    "print(full_text[:500] + \"...\")  # Show the first 500 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f002ed",
   "metadata": {},
   "source": [
    "# Whisper Medium Urdu\n",
    "### Done on the EC2 Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e08523e",
   "metadata": {},
   "source": [
    "# Assembly AI NANO MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcd13eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import assemblyai as aai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e85384ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"ASSEMBLY_KEY\")\n",
    "aai.settings.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87b28740",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = r\"Dataset\\Urban II\\918-IMCG I-8-4\\Debrief 1-918.m4a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc7bc8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = aai.TranscriptionConfig(speech_model=aai.SpeechModel.nano, language_code=\"ur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a99731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = aai.Transcriber(config=config).transcribe(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "518d2b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "if transcript.status == \"error\":\n",
    "  raise RuntimeError(f\"Transcription failed: {transcript.error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "334d098c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Full Transcript: \n",
      "\n",
      "مجھے کلاٹے złاتےLeftے ہیں؟ میرے بیخی بڑے انڈوائی کرتی ہے بیخی انڈوائی کلاٹی کرتی سکتا ہوں اے لئے اہم انiinوز کیلیے سبھی ہے بھی انہوں کے لیے ایک نئی چیزٹی کیا ہے وہ اسی ہی کنک کر پا رہے تھے کنک کر پا رہے تھے تو یہ ایک دو بھی جو مصنفت دیتا ہے کہ وہ پھر سمجھا تھا کہ اگر ہم شام کی اس کی بات کریں تو وہ پیم ہو گا اور اگر ہم جو بہت اس کی بات کریں تو وہ ایم ہو گا لیکن وہ بہت اچھے سب کنسرٹ کو کر لیا ویسے کہ ان پر سب کو پتھلا گیا تھا کہ ان کی سب کنگ دوکل کیا اکثر لیکھ ہوتا ہے کہ اس سے اس کے بچے نہیں سمجھتے کیونکہ اس سے اس سے اکہ مجیس سے انہوں نے سمجھا تھا کہ تو ان کے شخص میں کھو ایسے لگاتا ہے ان کا سب کے صورت ہے تو اپنے ذنان کے شخص میں ایم ہو گئے مرحبا ہوں کہ اُن نے نتی کانک کر دوکل کیا نا ، میں مجھے کیاFlash کرتا ہے ایک نیسرٹ میں ایک نیسرٹ میں اُتنا پوچھا اگر جب کلین سی کلینگ پیچھا ہے وہ دور کیا ہے نائی الحیت جاتا ہوا ہے وہ اگر پیچھنا پہلے جاتا ہے اور ایروپلینہ نہیں ہم چاہتے ہیں وہ انہوں نے ایک زیادہ ملشہ کر رہی ہے جو بھی ملشہ کر رہا ہی جاک کیوں پہلی تخزون ہم کرار اگر ہی دیتے ہیں بھی اکلہ اکلہ کرنا ہی تاکلہ ملشہ کرنا ہی تاکلہ بہت کھولی ہم انگر بھی ہوتے ہیں وہ جو اگر کر بھی چکتے تھے تو ان کیلے زیادہ جاتا بھی اگر ہی اداک ہے بسیورتی بسیورتی بہت جو بہت کار جاتا بھی اس سے ہمیں اردارے کیا کرتے ہیں کیا رہی ایک دفنن نے قرش سب ہر کرے گیا ہے اور اس کے لعا کیا کیا سلغا لگٹر کے لعا لگٹر کے لعا لگٹر کے لحظر لگٹر کے لحظر یہ جاسکتا تھا وان وان آرز کرکے نا ہمکہ بھی ٹائنکی جاسکتا تھا ساتھ بہت ایک ایم پر ایم سے بھی روائی سکتا تھا اسی کیا دے ہم جاتا ہے ایم پیم پر ہے اور مجھے لگا مجھے لگا 40 میٹس پس کے ٹائم پر ایم پر ہیٹ ہو جائے گا نا یہ بھی تھا کہ ہم پہلے کروا بھی چکے ہیں تب انہوں نے ایم پہلے ساتھ زیادہ نلگتا تھا ٹائم آجو جلدی وہ کر رہے تھے جب بھی کرتا تھا اسی بھی شاید جلدی وہ کر رہا تھا میں ایسی بھی کر رہا تھا نا ہمارے ایم لائے بھی چھوٹا تھا نا ہمارے ایم پر دو دن ہم نے پہلے چھوٹا ٹائم پر روائی سکتے تھے ہمارے بھی بھی میں نے لگے کیا ملتری دیکن ساتھ گئے تھا اس میں آگے جب یہ جئے ایم پر ہم نے شروع دکے تو لگا ہمارے تھا جس میں ہم نے بہت ہم سے ساتھ تھی جو اج workflows جس طرح تھے بہت جس طرح تھے آپی قلاص انہوں نے تحت اگر کلالشاید تجرینہتا تھے اور ایم پر انہوں تھے بھی مارے تھا اور ایم تحریکتی کا مئے اضاف ہوتے ہے ان گلالشاید کو اس طرح ایم پر سوچ مممیٹ کرنا کو لیگ concentration اس طلق ہی بڑی بات ہوتی ہے میں کسی آپ کو کسی بات سکتا ہے کہ یہ صرف آج کرا ہی ہے اس لن کیا کیوں کہ میں اپنی بہت مرکہ之後 کسچے میں پڑنے کی ضرورت ہزار جیسے ہیں بچوں کیا لیکن اپنی بالوںی تو آپ اپنی باروں میں ایک ہی لیگتے ہیں پڑ کے بیٹھنے کے دور تک میں سے Pom sopa اسا بھی جانائے گی provide جانائے organised بچے داؤن ہو جاتا ہے پیرہ للی چل چل رہی ہوتی ہے ایسے یہ آپ کی آتنی پاس میں دیکھتے ہیں اگر آپ کو بیٹ کرنے کے لیے نا مجھے لگتا ہے ہاں اسی لیے کلاس کی مجھے انگیڈ میں نظر ہے آپ کی نیڈ جی لیوڈ اس کا سیم تھا بچے بھی جرہا ہے اور دیکھا جب ایک بچی نے فجر والا ریسپونس کیا تو دوسی بچی کتنے اور سے سنی دیتے تو ہمیشہ سے مجھے اپنی بہت پرسنلی بہت پسند ہے تو بچوں کا تو وہ ایک من دیکھا کہ آپ کے ساتھ ریلیشن اس طرح وہ دوستانہ والا ریلیشن تھا تو اتنا وہ اچھا لگ رہا تھا اچھا لگ رہا تھا اتنی بڑی لگتداد کا بیحیویر سٹنگ اور all that آپ نے بہت اچھی سے کیا تھا میں نے ایک بنای دیکھا کہ بچا دسٹرٹ ہوئے یا ایک بچے سے کچھ کرنے ہوئے یا پھر لیکویچ سرہ کوئی بھی نہیں بیسیپلنٹرے بچے وہ ہاں شیر پنچل کرنا یہ تو ہر کلاس میں ہوتا ہے یہ تو ہر کلاس میں ہورا ہوتا ہے لیکن وہ لڑائی کیوں سکتر پہنے نہیں آیا تھے کہ ہم بتمیزی کر رہے ہیں یا ہم خیم چھنے اس طرح ہے تو اس کا بنای دیکھنے کی بیحیویر سٹنگ بہت اچھی کیوئی تھی لیکن last time میں اس میں ہم کی بیحیویر اور اس کے بھی آپ چھوڑا سا ہونا چاہیے لیکن آپ لارٹ فیال میں جسے مابیہ بچے کتنا ہی ہونا کروی کیسے یہ نا سمجھائے گی تو ایک لیمٹ آپ نے سیٹنگی کہ یہاں تک ہم نے اس طرح بھیحیو کرنا اور کلاس میں کی روز کیا ہوتے جب ہم سارت کرتے ہیں لیکٹر تو تب ہم نے کس طرح وہ کرنے تو آپ نے دونوں like اس کو گفری ٹائن میں بھی ہم یہ کر سکتے ہیں اور کلاس میں ہم پر یہ سیٹنگ کی بھی آپ نے یہ بہت ہی چیز ہے لیسن پرسیلٹیشن مرز ویریگر آپ نے اتنی ریپرسیلٹیشن کیوی تھی اور پر بوٹ پر درائنگ کر کے آپ نے اسی گھڑنیاں بنائی میہ اور اللہ قلق سے مٹ نائگر مٹک آپ نے ان کو کس طرح سمجھائے ویری ویلڈن اس کے ساتھ یہ کرتے ہیں اس طرح اس میں بچوں کے بچوں کو مجھب کروا رہتے تو وہ رسل میں اس کے دن میں ہمارے لیسن پرنی کندنگ کیا آپ نے یہ ملکے کیا تو وہ چیز مجھے بہت اچھی رہ گی اور بیحیویرز اگر آپ نے بہت اچھی سے اس کو اورکم کیا بس ایک چھوٹی سے مائنر سے چیز میں بڑھوں گی آپ نے جو ہوم اکپیویڈی دینا بچوں کو کیا آپ نے اس میں کیا گئی؟ آپ نے بچوں اس پر چوائیسز دیتی آپ اپنی مرزی سے میں چاہتی کہ وہ کلاس میں ہو جاتا آپ اپنی مرزی سے بتائیں کوئی بھی چار ڈائمیں جیسے بچے بتا رہے تھے کہ میں نے پوچھتے تھے کہ سبو میں یہ کرتی اپنی مرزی گھارے کے بتا ہر ایک لئے اپنی مرزی کا بتایا کوئی کہ رہتا میں اس کو کارٹون دیکھو کوئی کہ رہتی اب میں ریڈن پریکٹس چاہتی تھی کہ گھر میں پہلے جب کلاس ورک میں تو ہم نے پیج دے دیتے تھے وہ already کر چکے ہیں اب میں نے ان کو اس دفعیے چیز دیا کہ وہ کوئی سیوی اچھوکنے ایمپی وہ خود لکھیں اور جب پر جب وہ آئے وہ کل والا ہمورد چھوڑا سا چار پاس بچوں کا دیکھائیں تو دفعیت ہو جائے وہ بالتل میں آپ کی باس مجھے کے کلاس میں ہوا وہ جو چائیس دینا آپ نے کہ آپ اپنی مرزی سے کہہ رہے تھے وہ کلاس میں ہم ان سے تو چاہتے تھے کہ فجر کس طائم پڑھتے ہیں ہم اسلام ناشطہ کرتے ہیں ہم سکول کیونکہ سب کی آنے کا طائم سیم ہے تو ہم بچوں کو چاہتے ہیں پھر وہ ترمیش میں شف نہ دیں آپ چاہتے تھا ان کو دینا ہے کہ آپ کی باس چاہتے ہیں آپ نے یہ بات میں لانٹ دنر لانٹ دنر نہیں ہے آپ اپنی مرزی سے باتوں کے کئی چاہتا ہوں جس میں دو ایمہارے ہوں دو پی ایمہارے ہوں ہم وہ سبسیفک بو نہ کریں دو ایمہارے ہوں اور وہ آپ کی چاہتے ہیں وہ آپ میں ہمورد دیا میں چاہتے ہیں چاہتے ہیں پانچ میں بچ گئے تھے ان میں ٹائن میں رکھن بھی ہوجا تھا اور یہ کہتا ہے کہ وربلی اپنے مجھے دو این ستا دیں اگر یہ جب ہم کلاست میں کروا رہے تھے جب ہم نے بوک پیش کمپیل رہنا تھا میں دیسنگر جو گا تو پھر یہ کمپیل ہو جا رہنا تھا کیونکہ already وہ لیے ایٹوٹی بچے کر چھوٹی ہوئے تھے یا تو نوٹ بوک پی کم پی کر رہے تھے اور نوٹ بوک پی کروا رہے تھے پھر ان کے لیے وہ اس میں ہوجا تھا آپ نے دیکھتا ہے کہ بچی نے بڑا ڈیفرنٹ ہم ہم نور مل روٹین کے بارے میں چل رہے تھے اور وہ اس نے پھر بتائے کہ میں اس فارہ بھی پڑھتی پھر پیچے سے سب اٹھے کہ میں بھی پڑھتے تو اس طرح کیا ہوتا کہ اگر ہم ان کو یہ چوئے ستے دینا تو شاید آپ کے تین کہ آپ ڈیلر کا بتا دیتے ہیں یا وکھومبر کا بید بید بھی نا کوئی کہتا کہ میں تو امی کے ساتھ بزار بھی گیا تھا میں تو اپنے دوسری گھر بھی گیا تھا میں بردے پارٹی بھی گیا تو ان کو ڈیفرنٹ ڈیفرنٹ چیز ریاداتی کسی ایک دن تھے وہ چوئے کا وہ ایک کو کنسیپٹے کے بچوں وہ چوئے سے دیتا ہے اس سے بہت بڑا ہی ہے اس میں ہم جتنا کرائیں جتنا چاہتا ہے اتنا اچھا ہوگا تو بس ایک بہت مائنر سے چیز تھی جو کہ ہم نے\n"
     ]
    }
   ],
   "source": [
    "print(f\" \\nFull Transcript: \\n\\n{transcript.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e8c91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('assemblyai_transcript.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(transcript.text + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c5f447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
